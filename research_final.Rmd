---
title: "Statistical Analysis of Real/Fake Job Postings"
output: html_document
---

# 1. Research Aim

The goal of this project is to analyze job postings to identify characteristics that distinguish fraudulent (fake) postings from legitimate ones. This dataset contains approximately 18,000 job descriptions, of which about 800 are fake (phishing or other fraudulent activity).

**Research Questions:**

1.  Do fraudulent job postings offer different salary ranges compared to real ones?
2.  Is there a difference in description length between fake and real job postings?
3.  Are fraudulent postings more likely to have missing company profiles?
4.  Does location (specifically California) affect the probability of a posting being fraudulent?

**Project Outline:**

1.  Data Import and Overview
2.  Data Preprocessing (salary standardization, derived variables)
3.  Exploratory Data Analysis (EDA) with visualizations
4.  Hypothesis Testing (to be completed later)
5.  Logistic Regression Modeling (to be completed later)

------------------------------------------------------------------------

# 2. Data Import and Overview

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)

data <- read.csv("fake_job_postings.csv")
```

## 2.1 Dataset Structure

```{r}
cat("Dataset dimensions:", nrow(data), "rows x", ncol(data), "columns\n")
cat("\nColumn names:\n")
print(colnames(data))
```

```{r}
str(data)
```

## 2.2 Column Descriptions

The dataset contains the following variables:

| Variable              | Description                               |
|-----------------------|-------------------------------------------|
| `job_id`              | Unique identifier for each job posting    |
| `title`               | Job title                                 |
| `location`            | Location in format "Country, State, City" |
| `department`          | Department within the company             |
| `salary_range`        | Offered salary range (various formats)    |
| `company_profile`     | Text description of the company           |
| `description`         | Full job description text                 |
| `requirements`        | Job requirements                          |
| `benefits`            | Benefits offered                          |
| `telecommuting`       | Binary: 1 = remote work allowed           |
| `has_company_logo`    | Binary: 1 = company logo present          |
| `has_questions`       | Binary: 1 = screening questions present   |
| `employment_type`     | Full-time, Part-time, Contract, etc.      |
| `required_experience` | Experience level required                 |
| `required_education`  | Education level required                  |
| `industry`            | Industry category                         |
| `function`            | Job function/role category                |
| `fraudulent`          | **Target variable**: 1 = fake, 0 = real   |

```{r}
cat("Target variable distribution:\n")
table(data$fraudulent)
cat("\nFraudulent rate:", round(mean(data$fraudulent) * 100, 2), "%")
```

------------------------------------------------------------------------

# 3. Data Preprocessing

## 3.1 Salary Range Standardization

The salary_range column has inconsistent formats that need standardization:

-   Full format: "20000-28000" (already correct)
-   Abbreviated: "20-28" (needs conversion to thousands)
-   Zero values: "0-0" (should be treated as missing)
-   Empty/null values (missing data)

```{r}
# Examine current salary formats
cat("Sample of salary_range values:\n")
head(data$salary_range[data$salary_range != ""], 20)
```

```{r}
# Count non-empty salary entries
cat("Non-empty salary ranges:", sum(data$salary_range != ""), "\n")
cat("Empty salary ranges:", sum(data$salary_range == ""), "\n")
```

```{r}
standardize_salary <- function(salary_str) {
  # Return NA for empty or null values
  if (is.na(salary_str) || salary_str == "" || salary_str == "0-0") {
    return(c(NA, NA))
  }

  # Remove dollar signs, commas, and whitespace
  clean <- gsub("[$,\\s]", "", salary_str)

  # Extract lower and upper bounds
  parts <- str_split(clean, "-")[[1]]

  if (length(parts) != 2) {
    return(c(NA, NA))
  }

  lower <- as.numeric(parts[1])
  upper <- as.numeric(parts[2])

  # Handle zero values as NA
  if (!is.na(lower) && lower == 0) lower <- NA
  if (!is.na(upper) && upper == 0) upper <- NA

  # Standardize salary formats:
  # - If < 250: likely in thousands (e.g., "60-80" means 60k-80k) -> multiply by 1000
  # - If < 3000: likely monthly salary -> multiply by 12 to get annual
  # - Otherwise: already annual salary, keep as is
  if (!is.na(lower) && !is.na(upper)) {
    if (lower < 250 && upper < 250) {
      # Thousands format (e.g., 60-80 -> 60000-80000)
      lower <- lower * 1000
      upper <- upper * 1000
    } else if (lower < 3000 && upper < 3000) {
      # Monthly format -> convert to annual
      lower <- lower * 12
      upper <- upper * 12
    }
    # Otherwise keep as annual salary
  }

  return(c(lower, upper))
}

# Apply standardization
salary_standardized <- t(sapply(data$salary_range, standardize_salary))
data$salary_lower <- salary_standardized[, 1]
data$salary_upper <- salary_standardized[, 2]
data$salary_mid <- (data$salary_lower + data$salary_upper) / 2
```

```{r}
# Verify standardization
cat("Salary standardization results:\n")
cat("Valid salary entries:", sum(!is.na(data$salary_mid)), "\n")
cat("Missing salary entries:", sum(is.na(data$salary_mid)), "\n\n")

cat("Salary statistics (midpoint):\n")
summary(data$salary_mid[!is.na(data$salary_mid)])
```

## 3.2 Create Derived Variables for Analysis

Based on the hypotheses in the interim report, we need the following variables:

```{r}
data <- data %>%
  mutate(
    # Description length (number of characters)
    desc_length = nchar(as.character(description)),

    # Empty company profile indicator
    empty_profile = is.na(company_profile) | company_profile == "",

    # California location indicator
    is_california = grepl("^US, CA", location),

    # Entry-level experience indicator (for logistic regression)
    is_entry_level = required_experience %in% c("Entry level", "Not Applicable", "Internship") |
                     required_experience == "",

    # Has company logo (already binary)
    has_logo = has_company_logo == 1,

    # Salary category for visualization
    salary_category = case_when(
      is.na(salary_mid) ~ "Unknown",
      salary_mid < 20000 ~ "<20k",
      salary_mid < 50000 ~ "20k-50k",
      salary_mid < 100000 ~ "50k-100k",
      salary_mid < 200000 ~ "100k-200k",
      TRUE ~ ">200k"
    ),

    # Description length category
    desc_length_category = case_when(
      desc_length < 1000 ~ "<1000",
      desc_length < 4000 ~ "1000-4000",
      TRUE ~ ">4000"
    )
  )

# Convert salary_category to ordered factor
data$salary_category <- factor(data$salary_category,
                                levels = c("<20k", "20k-50k", "50k-100k", "100k-200k", ">200k", "Unknown"))

data$desc_length_category <- factor(data$desc_length_category,
                                     levels = c("<1000", "1000-4000", ">4000"))
```

## 3.3 Split Data by Fraudulent Status

```{r}
fraudulent_data <- data %>% filter(fraudulent == 1)
real_data <- data %>% filter(fraudulent == 0)

n_fake <- nrow(fraudulent_data)
n_real <- nrow(real_data)

cat("Real job postings:", n_real, "\n")
cat("Fraudulent job postings:", n_fake, "\n")
cat("Fraud rate:", round(n_fake / nrow(data) * 100, 2), "%\n")
```

------------------------------------------------------------------------

# 4. Exploratory Data Analysis (EDA)

## 4.1 Target Variable Distribution

```{r fig.width=8, fig.height=5}
ggplot(data, aes(x = factor(fraudulent), fill = factor(fraudulent))) +
  geom_bar() +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
  scale_fill_manual(values = c("0" = "#3498db", "1" = "#e74c3c"),
                    labels = c("Real", "Fraudulent")) +
  labs(title = "1. Ratio of Real (0) and Fraudulent (1) Vacancies",
       x = "Fraudulent (0=No, 1=Yes)",
       y = "Count",
       fill = "Type") +
  theme_minimal() +
  theme(legend.position = "right")
```

The dataset is highly imbalanced with approximately 95% real postings and 5% fraudulent ones. This class imbalance is important to consider for hypothesis testing and modeling.

## 4.2 Salary Analysis

### 4.2.1 Salary Distribution by Fraud Status

```{r fig.width=10, fig.height=5}
# Filter to only entries with valid salary data
salary_data <- data %>% filter(!is.na(salary_mid))

ggplot(salary_data, aes(x = salary_mid, fill = factor(fraudulent))) +
  geom_histogram(bins = 50, alpha = 0.7, position = "identity") +
  scale_fill_manual(values = c("0" = "#3498db", "1" = "#e74c3c"),
                    labels = c("Real", "Fraudulent")) +
  labs(title = "Salary Distribution: Real vs Fraudulent Postings",
       x = "Salary (Midpoint)",
       y = "Count",
       fill = "Type") +
  theme_minimal() +
  scale_x_continuous(labels = scales::comma) +
  coord_cartesian(xlim = c(0, 300000))
```

### 4.2.2 Fraud Probability by Salary Category

```{r fig.width=10, fig.height=5}
# Calculate fraud probability by salary category
salary_fraud_prob <- data %>%
  filter(salary_category != "Unknown") %>%
  group_by(salary_category) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_probability = mean(fraudulent),
    .groups = "drop"
  )

print(salary_fraud_prob)

ggplot(salary_fraud_prob, aes(x = salary_category, y = fraud_probability, fill = salary_category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(fraud_probability * 100, 1), "%")), vjust = -0.5) +
  scale_fill_manual(values = c("<20k" = "#9b59b6", "20k-50k" = "#e67e22",
                                "50k-100k" = "#3498db", "100k-200k" = "#1abc9c", ">200k" = "#e74c3c")) +
  labs(title = "Do Scammers Lure You with High Salaries?",
       subtitle = "(Probability of fake depending on the amount)",
       x = "Salary",
       y = "Probability of Fraud") +
  theme_minimal() +
  theme(legend.position = "none")
```

This visualization shows whether fraudulent postings tend to offer unrealistically high salaries to attract victims.

### 4.2.3 Salary Statistics by Group

```{r}
cat("=== Salary Statistics ===\n\n")

cat("REAL postings with salary data:", sum(!is.na(real_data$salary_mid)), "\n")
cat("Mean salary:", round(mean(real_data$salary_mid, na.rm = TRUE), 2), "\n")
cat("Median salary:", round(median(real_data$salary_mid, na.rm = TRUE), 2), "\n")
cat("SD:", round(sd(real_data$salary_mid, na.rm = TRUE), 2), "\n\n")

cat("FRAUDULENT postings with salary data:", sum(!is.na(fraudulent_data$salary_mid)), "\n")
cat("Mean salary:", round(mean(fraudulent_data$salary_mid, na.rm = TRUE), 2), "\n")
cat("Median salary:", round(median(fraudulent_data$salary_mid, na.rm = TRUE), 2), "\n")
cat("SD:", round(sd(fraudulent_data$salary_mid, na.rm = TRUE), 2), "\n")
```

## 4.3 Description Length Analysis

### 4.3.1 Description Length Distribution

```{r fig.width=10, fig.height=5}
ggplot(data, aes(x = desc_length, fill = factor(fraudulent))) +
  geom_histogram(bins = 50, alpha = 0.7, position = "identity") +
  scale_fill_manual(values = c("0" = "#3498db", "1" = "#e74c3c"),
                    labels = c("Real", "Fraudulent")) +
  labs(title = "Description Length Distribution: Real vs Fraudulent",
       x = "Description Length (characters)",
       y = "Count",
       fill = "Type") +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 15000))
```

### 4.3.2 Fraud Probability by Description Length

```{r fig.width=10, fig.height=5}
desc_fraud_prob <- data %>%
  group_by(desc_length_category) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_probability = mean(fraudulent),
    .groups = "drop"
  )

print(desc_fraud_prob)

ggplot(desc_fraud_prob, aes(x = desc_length_category, y = fraud_probability, fill = desc_length_category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(fraud_probability * 100, 1), "%")), vjust = -0.5) +
  scale_fill_manual(values = c("<1000" = "#3498db", "1000-4000" = "#2ecc71", ">4000" = "#1abc9c")) +
  labs(title = "Do Scammers Write Shorter Texts?",
       subtitle = "(Probability of fake depending on the number of characters)",
       x = "Length of Text",
       y = "Probability of Fraud") +
  theme_minimal() +
  theme(legend.position = "none")
```

### 4.3.3 Description Length Statistics

```{r}
cat("=== Description Length Statistics ===\n\n")

cat("REAL postings:\n")
cat("Mean length:", round(mean(real_data$desc_length, na.rm = TRUE), 2), "characters\n")
cat("Median length:", round(median(real_data$desc_length, na.rm = TRUE), 2), "characters\n")
cat("SD:", round(sd(real_data$desc_length, na.rm = TRUE), 2), "\n\n")

cat("FRAUDULENT postings:\n")
cat("Mean length:", round(mean(fraudulent_data$desc_length, na.rm = TRUE), 2), "characters\n")
cat("Median length:", round(median(fraudulent_data$desc_length, na.rm = TRUE), 2), "characters\n")
cat("SD:", round(sd(fraudulent_data$desc_length, na.rm = TRUE), 2), "\n")
```

## 4.4 Company Profile Analysis

### 4.4.1 Missing Company Profile by Fraud Status

```{r fig.width=10, fig.height=5}
profile_data <- data %>%
  mutate(missing_profile = ifelse(empty_profile, "True", "False")) %>%
  group_by(missing_profile, fraudulent) %>%
  summarise(count = n(), .groups = "drop")

ggplot(profile_data, aes(x = missing_profile, y = count, fill = factor(fraudulent))) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = count), position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("0" = "#1abc9c", "1" = "#e74c3c"),
                    labels = c("Real (0)", "Fraudulent (1)")) +
  labs(title = "3. The Impact of Missing Company Descriptions on Fraud",
       x = "missing_profile",
       y = "Count",
       fill = "fraudulent") +
  theme_minimal()
```

### 4.4.2 Empty Profile Statistics

```{r}
cat("=== Empty Company Profile Statistics ===\n\n")

cat("REAL postings:\n")
cat("With empty profile:", sum(real_data$empty_profile), "/", n_real,
    "=", round(mean(real_data$empty_profile) * 100, 2), "%\n\n")

cat("FRAUDULENT postings:\n")
cat("With empty profile:", sum(fraudulent_data$empty_profile), "/", n_fake,
    "=", round(mean(fraudulent_data$empty_profile) * 100, 2), "%\n")
```

## 4.5 Location Analysis (California Focus)

### 4.5.1 Fraud Rate by Location

```{r fig.width=10, fig.height=5}
location_data <- data %>%
  mutate(location_type = ifelse(is_california, "California", "Other")) %>%
  group_by(location_type) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_rate = mean(fraudulent),
    .groups = "drop"
  )

print(location_data)

ggplot(location_data, aes(x = location_type, y = fraud_rate, fill = location_type)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(fraud_rate * 100, 2), "%")), vjust = -0.5) +
  scale_fill_manual(values = c("California" = "#e74c3c", "Other" = "#3498db")) +
  labs(title = "Fraud Rate: California vs Other Locations",
       x = "Location",
       y = "Fraud Rate") +
  theme_minimal() +
  theme(legend.position = "none")
```

### 4.5.2 Top Countries by Posting Count

```{r fig.width=10, fig.height=6}
# Extract country from location
data$country <- sapply(strsplit(as.character(data$location), ","), function(x) trimws(x[1]))

country_stats <- data %>%
  group_by(country) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_rate = mean(fraudulent),
    .groups = "drop"
  ) %>%
  filter(total >= 50) %>%  # Only countries with at least 50 postings
  arrange(desc(total)) %>%
  head(15)

print(country_stats)

ggplot(country_stats, aes(x = reorder(country, total), y = total, fill = fraud_rate)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_fill_gradient(low = "#3498db", high = "#e74c3c") +
  labs(title = "Top 15 Countries by Job Postings",
       x = "Country",
       y = "Number of Postings",
       fill = "Fraud Rate") +
  theme_minimal()
```

## 4.6 Employment Type Analysis

```{r fig.width=10, fig.height=5}
emp_type_stats <- data %>%
  filter(employment_type != "") %>%
  group_by(employment_type) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_rate = mean(fraudulent),
    .groups = "drop"
  ) %>%
  arrange(desc(total))

print(emp_type_stats)

ggplot(emp_type_stats, aes(x = reorder(employment_type, -fraud_rate), y = fraud_rate, fill = employment_type)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(fraud_rate * 100, 1), "%")), vjust = -0.5, size = 3) +
  labs(title = "Fraud Rate by Employment Type",
       x = "Employment Type",
       y = "Fraud Rate") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

## 4.7 Required Experience Analysis

```{r fig.width=10, fig.height=5}
exp_stats <- data %>%
  filter(required_experience != "") %>%
  group_by(required_experience) %>%
  summarise(
    total = n(),
    fraudulent_count = sum(fraudulent),
    fraud_rate = mean(fraudulent),
    .groups = "drop"
  ) %>%
  arrange(desc(fraud_rate))

print(exp_stats)

ggplot(exp_stats, aes(x = reorder(required_experience, -fraud_rate), y = fraud_rate, fill = required_experience)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(fraud_rate * 100, 1), "%")), vjust = -0.5, size = 3) +
  labs(title = "Fraud Rate by Required Experience Level",
       subtitle = "Do scammers target inexperienced candidates?",
       x = "Required Experience",
       y = "Fraud Rate") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

## 4.8 Binary Features Analysis

```{r fig.width=12, fig.height=5}
# Analyze binary features: telecommuting, has_company_logo, has_questions
binary_features <- data %>%
  summarise(
    telecommuting_fraud_rate_0 = mean(fraudulent[telecommuting == 0]),
    telecommuting_fraud_rate_1 = mean(fraudulent[telecommuting == 1]),
    logo_fraud_rate_0 = mean(fraudulent[has_company_logo == 0]),
    logo_fraud_rate_1 = mean(fraudulent[has_company_logo == 1]),
    questions_fraud_rate_0 = mean(fraudulent[has_questions == 0]),
    questions_fraud_rate_1 = mean(fraudulent[has_questions == 1])
  )

binary_df <- data.frame(
  Feature = rep(c("Telecommuting", "Has Company Logo", "Has Questions"), each = 2),
  Value = rep(c("No (0)", "Yes (1)"), 3),
  FraudRate = c(
    binary_features$telecommuting_fraud_rate_0, binary_features$telecommuting_fraud_rate_1,
    binary_features$logo_fraud_rate_0, binary_features$logo_fraud_rate_1,
    binary_features$questions_fraud_rate_0, binary_features$questions_fraud_rate_1
  )
)

ggplot(binary_df, aes(x = Feature, y = FraudRate, fill = Value)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = paste0(round(FraudRate * 100, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +
  scale_fill_manual(values = c("No (0)" = "#e74c3c", "Yes (1)" = "#2ecc71")) +
  labs(title = "Fraud Rate by Binary Features",
       x = "Feature",
       y = "Fraud Rate",
       fill = "Value") +
  theme_minimal()
```

Postings WITHOUT company logos and WITHOUT screening questions have significantly higher fraud rates.

------------------------------------------------------------------------

# 5. Summary of EDA Findings

```{r}
cat("=== KEY FINDINGS FROM EDA ===\n\n")

cat("1. CLASS IMBALANCE:\n")
cat("   - Dataset is highly imbalanced (~95% real, ~5% fake)\n\n")

cat("2. SALARY PATTERNS:\n")
cat("   - Real postings mean salary:", round(mean(real_data$salary_mid, na.rm = TRUE), 0), "\n")
cat("   - Fake postings mean salary:", round(mean(fraudulent_data$salary_mid, na.rm = TRUE), 0), "\n")
cat("   - Very high salaries (>200k) show elevated fraud rates\n\n")

cat("3. DESCRIPTION LENGTH:\n")
cat("   - Real postings mean length:", round(mean(real_data$desc_length), 0), "chars\n")
cat("   - Fake postings mean length:", round(mean(fraudulent_data$desc_length), 0), "chars\n\n")

cat("4. COMPANY PROFILE:\n")
cat("   - Real postings missing profile:", round(mean(real_data$empty_profile) * 100, 1), "%\n")
cat("   - Fake postings missing profile:", round(mean(fraudulent_data$empty_profile) * 100, 1), "%\n\n")

cat("5. BINARY FEATURES:\n")
cat("   - Postings without company logo have higher fraud rate\n")
cat("   - Postings without screening questions have higher fraud rate\n")
```

------------------------------------------------------------------------

# 6. Data Prepared for Hypothesis Testing

The following variables are now ready for hypothesis testing:

```{r}
# Extract variables needed for hypothesis testing
salary_fraud <- fraudulent_data %>% filter(!is.na(salary_mid)) %>% pull(salary_mid)
salary_real <- real_data %>% filter(!is.na(salary_mid)) %>% pull(salary_mid)

fraud_desc <- fraudulent_data %>% pull(desc_length)
real_desc <- real_data %>% pull(desc_length)

fraud_profiles <- fraudulent_data %>% pull(empty_profile)
real_profiles <- real_data %>% pull(empty_profile)

california_posts <- data %>% filter(is_california == TRUE)
other_posts <- data %>% filter(is_california == FALSE)

cat("Variables ready for hypothesis testing:\n")
cat("- salary_fraud:", length(salary_fraud), "observations\n")
cat("- salary_real:", length(salary_real), "observations\n")
cat("- fraud_desc:", length(fraud_desc), "observations\n")
cat("- real_desc:", length(real_desc), "observations\n")
cat("- California posts:", nrow(california_posts), "\n")
cat("- Other location posts:", nrow(other_posts), "\n")

n_salary_fraud <- length(salary_fraud)
n_salary_real <- length(salary_real)
```

------------------------------------------------------------------------

# 7. Hypothesis Testing

## 7.1 Hypothesis 1: Mean Salary Comparison

**Research Question:** Do fraudulent job postings offer different salary ranges compared to real ones?

We test:

-   $H_0$: Mean salary of fraudulent postings equals mean salary of real postings.
-   $H_1$: Mean salary of fraudulent postings differs from mean salary of real postings.

$$
H_0: \mu_F = \mu_R, \qquad H_1: \mu_F \neq \mu_R
$$

**Assumptions:** We assume that salaries in both groups are independent and normally distributed with a common variance.

**Test Statistic:** We use the classical two-sample Student's t-test with pooled variance.

The pooled sample variance is: $$
S_p^2 = \frac{(n_F - 1)S_F^2 + (n_R - 1)S_R^2}{n_F + n_R - 2}
$$

The test statistic is: $$
T = \frac{\bar{X}_F - \bar{X}_R}{S_p \sqrt{\frac{1}{n_F} + \frac{1}{n_R}}}
$$

Under the null hypothesis: $$
T \sim t_{n_F + n_R - 2}
$$

```{r}
# Calculate sample statistics
x_bar_F <- mean(salary_fraud)
x_bar_R <- mean(salary_real)

s2_F <- var(salary_fraud)
s2_R <- var(salary_real)

# Pooled variance
s2_p <- ((n_salary_fraud - 1) * s2_F + (n_salary_real - 1) * s2_R) / (n_salary_fraud + n_salary_real - 2)
s_p <- sqrt(s2_p)

# T-statistic
T_stat <- (x_bar_F - x_bar_R) / (s_p * sqrt(1/n_salary_fraud + 1/n_salary_real))

# Degrees of freedom
df_t <- n_salary_fraud + n_salary_real - 2

# Two-sided p-value
p_value <- 2 * pt(-abs(T_stat), df = df_t)

cat("=== Hypothesis 1: Two-Sample T-Test for Salary ===\n\n")
cat("Sample sizes:\n")
cat("  Fraudulent (n_F):", n_salary_fraud, "\n")
cat("  Real (n_R):", n_salary_real, "\n\n")

cat("Sample means:\n")
cat("  Mean (Fraudulent):", round(x_bar_F, 2), "\n")
cat("  Mean (Real):", round(x_bar_R, 2), "\n\n")

cat("Sample variances:\n")
cat("  Var (Fraudulent):", round(s2_F, 2), "\n")
cat("  Var (Real):", round(s2_R, 2), "\n\n")

cat("Pooled SD:", round(s_p, 2), "\n")
cat("T-statistic:", round(T_stat, 4), "\n")
cat("Degrees of freedom:", df_t, "\n")
cat("P-value:", format(p_value, scientific = TRUE, digits = 4), "\n")
```

```{r}
# Verify with built-in t.test function
t.test(salary_fraud, salary_real, var.equal = TRUE)
```

```{r}
# Decision
alpha <- 0.05
cat("=== Decision (alpha =", alpha, ") ===\n\n")
if (p_value < alpha) {
  cat("Reject H0: Mean salary of fraudulent postings significantly differs from mean salary of real postings.\n")
} else {
  cat("Fail to reject H0: No significant difference in mean salary between fraudulent and real postings.\n")
}
```

------------------------------------------------------------------------

## 7.2 Hypothesis 2: Description Length Comparison

**Research Question:** Is there a difference in description length between fake and real job postings?

We test two one-sided alternatives:

**Test 2a:** $$
H_0: \mu_F = \mu_R, \qquad H_1: \mu_F > \mu_R
$$ (Fraudulent postings have longer descriptions)

**Test 2b:** $$
H_0: \mu_F = \mu_R, \qquad H_1: \mu_F < \mu_R
$$ (Fraudulent postings have shorter descriptions)

**Test Statistic:** The same pooled-variance t-statistic is used: $$
T = \frac{\bar{L}_F - \bar{L}_R}{S_p \sqrt{\frac{1}{n_F} + \frac{1}{n_R}}}
$$

**Decision Rules:** $$
\text{Reject } H_0 \text{ if } T > t_{\alpha, n_F+n_R-2} \quad (\text{for } H_1: \mu_F > \mu_R)
$$ $$
\text{Reject } H_0 \text{ if } T < -t_{\alpha, n_F+n_R-2} \quad (\text{for } H_1: \mu_F < \mu_R)
$$

```{r}
# Calculate sample statistics for description length
mean_fraud_desc <- mean(fraud_desc, na.rm = TRUE)
mean_real_desc <- mean(real_desc, na.rm = TRUE)

var_fraud_desc <- var(fraud_desc, na.rm = TRUE)
var_real_desc <- var(real_desc, na.rm = TRUE)

# Pooled variance
pooled_var_desc <- ((n_fake - 1) * var_fraud_desc + (n_real - 1) * var_real_desc) / (n_fake + n_real - 2)
pooled_sd_desc <- sqrt(pooled_var_desc)

# T-statistic
T_desc <- (mean_fraud_desc - mean_real_desc) / (pooled_sd_desc * sqrt(1/n_fake + 1/n_real))

# Degrees of freedom
df_desc <- n_fake + n_real - 2

# Critical value for one-sided test
alpha_desc <- 0.05
t_crit_desc <- qt(1 - alpha_desc, df = df_desc)

# P-values for one-sided tests
p_greater_desc <- 1 - pt(T_desc, df = df_desc)  # H1: mu_F > mu_R
p_less_desc <- pt(T_desc, df = df_desc)          # H1: mu_F < mu_R

cat("=== Hypothesis 2: One-Sided T-Tests for Description Length ===\n\n")
cat("Sample sizes:\n")
cat("  Fraudulent (n_F):", n_fake, "\n")
cat("  Real (n_R):", n_real, "\n\n")

cat("Sample means:\n")
cat("  Mean (Fraudulent):", round(mean_fraud_desc, 2), "characters\n")
cat("  Mean (Real):", round(mean_real_desc, 2), "characters\n\n")

cat("Pooled SD:", round(pooled_sd_desc, 2), "\n")
cat("T-statistic:", round(T_desc, 4), "\n")
cat("Degrees of freedom:", df_desc, "\n")
cat("Critical value (one-sided, alpha=0.05):", round(t_crit_desc, 4), "\n\n")

cat("--- Test 2a: H1: mu_F > mu_R (fraudulent longer) ---\n")
cat("P-value:", format(p_greater_desc, scientific = TRUE, digits = 4), "\n")
cat("Reject H0:", T_desc > t_crit_desc, "\n\n")

cat("--- Test 2b: H1: mu_F < mu_R (fraudulent shorter) ---\n")
cat("P-value:", format(p_less_desc, scientific = TRUE, digits = 4), "\n")
cat("Reject H0:", T_desc < -t_crit_desc, "\n")
```

```{r}
# Verify with built-in t.test function
cat("=== Verification with t.test() ===\n\n")
cat("Test 2a (alternative: greater):\n")
t.test(fraud_desc, real_desc, var.equal = TRUE, alternative = "greater")
```

```{r}
cat("Test 2b (alternative: less):\n")
t.test(fraud_desc, real_desc, var.equal = TRUE, alternative = "less")
```

```{r}
# Decision
cat("=== Decision (alpha = 0.05) ===\n\n")
if (T_desc > t_crit_desc) {
  cat("Test 2a: Reject H0 - Fraudulent postings have significantly LONGER descriptions.\n")
} else if (T_desc < -t_crit_desc) {
  cat("Test 2b: Reject H0 - Fraudulent postings have significantly SHORTER descriptions.\n")
} else {
  cat("Fail to reject H0 - No significant difference in description length.\n")
}
```

------------------------------------------------------------------------

## 7.3 Hypothesis 3: Empty Company Profile Proportion

**Research Question:** Are fraudulent postings more likely to have missing company profiles?

We compare proportions of empty company profiles between real and fraudulent postings.

Let: $$
\hat{p}_R = \frac{X_R}{n_R}, \qquad \hat{p}_F = \frac{X_F}{n_F}
$$ where $X_R$ and $X_F$ are the numbers of postings with empty company profiles.

**Test 3a:** $$
H_0: p_R = p_F, \qquad H_1: p_R > p_F
$$ (Real postings have MORE empty profiles)

**Test 3b:** $$
H_0: p_R = p_F, \qquad H_1: p_R < p_F
$$ (Real postings have FEWER empty profiles, i.e., fraudulent have more)

**Test Statistic:** The pooled proportion under $H_0$ is: $$
\hat{p} = \frac{X_R + X_F}{n_R + n_F}
$$

The z-statistic is: $$
Z = \frac{\hat{p}_R - \hat{p}_F}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_R} + \frac{1}{n_F}\right)}}
$$

Under the null hypothesis: $$
Z \sim N(0, 1)
$$

```{r}
# Count empty profiles in each group
x_real_prof <- sum(real_profiles)
x_fraud_prof <- sum(fraud_profiles)

# Sample proportions
p_hat_real_prof <- x_real_prof / n_real
p_hat_fraud_prof <- x_fraud_prof / n_fake

# Pooled proportion
p_pooled_prof <- (x_real_prof + x_fraud_prof) / (n_real + n_fake)

# Z-statistic
Z_prof <- (p_hat_real_prof - p_hat_fraud_prof) / sqrt(p_pooled_prof * (1 - p_pooled_prof) * (1/n_real + 1/n_fake))

# Critical value for one-sided test
alpha_prof <- 0.05
z_crit_prof <- qnorm(1 - alpha_prof)

# P-values for one-sided tests
p_val_greater_prof <- 1 - pnorm(Z_prof)  # H1: p_R > p_F
p_val_less_prof <- pnorm(Z_prof)          # H1: p_R < p_F

cat("=== Hypothesis 3: Two-Sample Z-Test for Proportions ===\n\n")
cat("Empty profiles count:\n")
cat("  Real:", x_real_prof, "/", n_real, "=", round(p_hat_real_prof * 100, 2), "%\n")
cat("  Fraudulent:", x_fraud_prof, "/", n_fake, "=", round(p_hat_fraud_prof * 100, 2), "%\n\n")

cat("Pooled proportion:", round(p_pooled_prof, 4), "\n")
cat("Z-statistic:", round(Z_prof, 4), "\n")
cat("Critical value (one-sided, alpha=0.05):", round(z_crit_prof, 4), "\n\n")

cat("--- Test 3a: H1: p_R > p_F (real have more empty profiles) ---\n")
cat("P-value:", format(p_val_greater_prof, scientific = TRUE, digits = 4), "\n")
cat("Reject H0:", Z_prof > z_crit_prof, "\n\n")

cat("--- Test 3b: H1: p_R < p_F (fraudulent have more empty profiles) ---\n")
cat("P-value:", format(p_val_less_prof, scientific = TRUE, digits = 4), "\n")
cat("Reject H0:", Z_prof < -z_crit_prof, "\n")
```

```{r}
# Verify with built-in prop.test function
cat("=== Verification with prop.test() ===\n\n")
cat("Test 3a (alternative: greater):\n")
prop.test(x = c(x_real_prof, x_fraud_prof), n = c(n_real, n_fake), alternative = "greater", correct = FALSE)
```

```{r}
cat("Test 3b (alternative: less):\n")
prop.test(x = c(x_real_prof, x_fraud_prof), n = c(n_real, n_fake), alternative = "less", correct = FALSE)
```

```{r}
# Decision
cat("=== Decision (alpha = 0.05) ===\n\n")
if (Z_prof > z_crit_prof) {
  cat("Test 3a: Reject H0 - Real postings have significantly MORE empty profiles.\n")
} else if (Z_prof < -z_crit_prof) {
  cat("Test 3b: Reject H0 - Fraudulent postings have significantly MORE empty profiles.\n")
} else {
  cat("Fail to reject H0 - No significant difference in empty profile proportions.\n")
}
```

------------------------------------------------------------------------

## 7.4 Hypothesis 4: California Location and Fraud Rate

**Research Question:** Does the probability that a job posting is fraudulent change when the posting is located in California?

Let: - $p_{CA}$ = probability of fraud for California postings - $p_{Other}$ = probability of fraud for non-California postings

$$
H_0: p_{CA} = p_{Other}, \qquad H_1: p_{CA} > p_{Other}
$$

**Test Statistic:** $$
Z = \frac{\hat{p}_{CA} - \hat{p}_{Other}}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_{CA}} + \frac{1}{n_{Other}}\right)}}
$$

**Decision Rule:** $$
\text{Reject } H_0 \text{ if } Z > z_\alpha
$$

```{r}
# Count fraudulent postings by location
n_california <- nrow(california_posts)
n_other <- nrow(other_posts)

x_fraud_cal <- sum(california_posts$fraudulent == 1)
x_fraud_other <- sum(other_posts$fraudulent == 1)

# Sample proportions (fraud rates)
p_hat_cal <- x_fraud_cal / n_california
p_hat_other <- x_fraud_other / n_other

# Pooled proportion
p_pooled_loc <- (x_fraud_cal + x_fraud_other) / (n_california + n_other)

# Z-statistic
Z_loc <- (p_hat_cal - p_hat_other) / sqrt(p_pooled_loc * (1 - p_pooled_loc) * (1/n_california + 1/n_other))

# Critical value
alpha_loc <- 0.05
z_crit_loc <- qnorm(1 - alpha_loc)

# P-value for one-sided test (H1: p_CA > p_Other)
p_val_loc <- 1 - pnorm(Z_loc)

cat("=== Hypothesis 4: Z-Test for California Fraud Rate ===\n\n")
cat("Sample sizes:\n")
cat("  California postings:", n_california, "\n")
cat("  Other locations:", n_other, "\n\n")

cat("Fraudulent counts:\n")
cat("  California:", x_fraud_cal, "/", n_california, "=", round(p_hat_cal * 100, 2), "%\n")
cat("  Other:", x_fraud_other, "/", n_other, "=", round(p_hat_other * 100, 2), "%\n\n")

cat("Pooled proportion:", round(p_pooled_loc, 4), "\n")
cat("Z-statistic:", round(Z_loc, 4), "\n")
cat("Critical value (one-sided, alpha=0.05):", round(z_crit_loc, 4), "\n")
cat("P-value:", format(p_val_loc, scientific = TRUE, digits = 4), "\n")
```

```{r}
# Verify with built-in prop.test function
cat("=== Verification with prop.test() ===\n")
prop.test(x = c(x_fraud_cal, x_fraud_other), n = c(n_california, n_other), alternative = "greater", correct = FALSE)
```

```{r}
# Decision
cat("=== Decision (alpha = 0.05) ===\n\n")
if (Z_loc > z_crit_loc) {
  cat("Reject H0: California postings have significantly HIGHER fraud rate than other locations.\n")
} else {
  cat("Fail to reject H0: No significant difference in fraud rate between California and other locations.\n")
}
```

------------------------------------------------------------------------

# 8. Summary of Hypothesis Testing Results

```{r}
cat("=== SUMMARY OF ALL HYPOTHESIS TESTS ===\n\n")

cat("HYPOTHESIS 1: Mean Salary Comparison (Two-sided t-test)\n")
cat("  H0: mu_F = mu_R vs H1: mu_F != mu_R\n")
cat("  T-statistic:", round(T_stat, 4), ", p-value:", format(p_value, scientific = TRUE, digits = 4), "\n")
cat("  Result:", ifelse(p_value < 0.05, "REJECT H0", "FAIL TO REJECT H0"), "\n\n")

cat("HYPOTHESIS 2: Description Length (One-sided t-tests)\n")
cat("  T-statistic:", round(T_desc, 4), "\n")
cat("  2a) H1: mu_F > mu_R, p-value:", format(p_greater_desc, scientific = TRUE, digits = 4),
    ", Result:", ifelse(T_desc > t_crit_desc, "REJECT H0", "FAIL TO REJECT H0"), "\n")
cat("  2b) H1: mu_F < mu_R, p-value:", format(p_less_desc, scientific = TRUE, digits = 4),
    ", Result:", ifelse(T_desc < -t_crit_desc, "REJECT H0", "FAIL TO REJECT H0"), "\n\n")

cat("HYPOTHESIS 3: Empty Company Profile Proportion (Z-tests)\n")
cat("  Z-statistic:", round(Z_prof, 4), "\n")
cat("  3a) H1: p_R > p_F, p-value:", format(p_val_greater_prof, scientific = TRUE, digits = 4),
    ", Result:", ifelse(Z_prof > z_crit_prof, "REJECT H0", "FAIL TO REJECT H0"), "\n")
cat("  3b) H1: p_R < p_F, p-value:", format(p_val_less_prof, scientific = TRUE, digits = 4),
    ", Result:", ifelse(Z_prof < -z_crit_prof, "REJECT H0", "FAIL TO REJECT H0"), "\n\n")

cat("HYPOTHESIS 4: California Fraud Rate (One-sided Z-test)\n")
cat("  H0: p_CA = p_Other vs H1: p_CA > p_Other\n")
cat("  Z-statistic:", round(Z_loc, 4), ", p-value:", format(p_val_loc, scientific = TRUE, digits = 4), "\n")
cat("  Result:", ifelse(Z_loc > z_crit_loc, "REJECT H0", "FAIL TO REJECT H0"), "\n")
```

------------------------------------------------------------------------

# 9. Logistic Regression

In the previous sections we compared means and proportions between real and fraudulent postings using classical parametric tests. We now move to a binary classifier - logistic regression, which allows us to model the probability that a posting is fraudulent as a function of several predictors simultaneously.

## 9.1 Model Specification

Let:

-   $Y_i \in \{0, 1\}$ be the response for posting $i$, where $Y_i = 1$ if the posting is fraudulent and $Y_i = 0$ if it is real
-   $X_i = (x_{i1}, \ldots, x_{ip})^\top$ be the vector of predictors for posting $i$ (e.g., salary range, length of description, missing company profile, location, required experience, etc.)
-   $\pi_i = P(Y_i = 1 | X_i)$ be the conditional probability that posting $i$ is fraudulent

The logistic regression model assumes that: $$
Y_i | X_i \sim \text{Bernoulli}(\pi_i)
$$

and the log-odds (logit) of fraud are a linear function of the predictors: $$
\log \frac{\pi_i}{1 - \pi_i} = \eta_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
$$

Equivalently, the conditional probability has the form: $$
\pi_i = P(Y_i = 1 | X_i) = \frac{\exp(\eta_i)}{1 + \exp(\eta_i)}
$$

For each coefficient $\beta_j$ ($j = 1, \ldots, p$), the quantity $\exp(\beta_j)$ is the **odds ratio** associated with a one-unit increase in $x_{ij}$, holding all other predictors fixed.

## 9.2 Estimation

The parameters $\beta = (\beta_0, \ldots, \beta_p)^\top$ are estimated by **maximum likelihood**. The likelihood function is: $$
L(\beta) = \prod_{i=1}^{n} \pi_i^{Y_i} (1 - \pi_i)^{1-Y_i}
$$

where $\pi_i = \pi_i(\beta)$ depends on $\beta$ through the logistic link.

We typically work with the log-likelihood: $$
\ell(\beta) = \sum_{i=1}^{n} [Y_i \log(\pi_i) + (1 - Y_i) \log(1 - \pi_i)]
$$

There is no closed-form solution for $\hat{\beta}$, so numerical optimization (e.g., iteratively reweighted least squares) is used to obtain the maximum likelihood estimator (MLE) $\hat{\beta}$ and its estimated covariance matrix $\widehat{\text{Var}}(\hat{\beta})$.

## 9.3 Wald Tests for Individual Coefficients

For each predictor $x_{ij}$, we can test whether it has a statistically significant effect on fraud probability.

**Two-sided test** (no prior about the sign). For coefficient $\beta_j$: $$
H_0: \beta_j = 0 \quad \text{vs.} \quad H_1: \beta_j \neq 0
$$

Let $\hat{\beta}_j$ be the estimate and $\widehat{\text{se}}(\hat{\beta}_j)$ its standard error. The Wald statistic is: $$
Z_j = \frac{\hat{\beta}_j}{\widehat{\text{se}}(\hat{\beta}_j)}
$$

Under $H_0$ and for large $n$: $$
Z_j \approx N(0, 1)
$$

Decision rule at significance level $\alpha$: $$
\text{Reject } H_0 \text{ if } |Z_j| > z_{1-\alpha/2}
$$

**One-sided test** (directional hypotheses). If we have prior expectations about the sign of $\beta_j$: $$
H_0: \beta_j = 0, \quad H_1: \beta_j > 0 \quad \text{(predictor increases odds of fraud)}
$$ or $$
H_0: \beta_j = 0, \quad H_1: \beta_j < 0 \quad \text{(predictor decreases odds of fraud)}
$$

The rejection regions are: $$
\text{Reject } H_0 \text{ if } Z_j > z_{1-\alpha} \quad \text{for } H_1: \beta_j > 0
$$ $$
\text{Reject } H_0 \text{ if } Z_j < -z_{1-\alpha} \quad \text{for } H_1: \beta_j < 0
$$

## 9.4 Prepare Data for Logistic Regression

```{r}
# Create a clean dataset for logistic regression
model_data <- data %>%
  mutate(
    # Standardize salary (use midpoint, fill NA with median)
    salary_standardized = ifelse(is.na(salary_mid), median(salary_mid, na.rm = TRUE), salary_mid),
    salary_standardized = scale(salary_standardized)[,1],

    # Standardize description length
    desc_length_standardized = scale(desc_length)[,1],

    # Binary: missing company profile
    missing_profile = as.integer(empty_profile),

    # Binary: entry-level or no experience required
    entry_level = as.integer(required_experience %in% c("Entry level", "Not Applicable", "Internship", "")),

    # Binary: has company logo
    has_logo = has_company_logo,

    # Binary: has screening questions
    has_questions = has_questions,

    # Binary: telecommuting allowed
    telecommuting = telecommuting,

    # Binary: California location
    california = as.integer(is_california)
  ) %>%
  select(fraudulent, salary_standardized, desc_length_standardized, missing_profile,
         entry_level, has_logo, has_questions, telecommuting, california)

cat("Model data prepared:\n")
cat("Observations:", nrow(model_data), "\n")
cat("Variables:", ncol(model_data), "\n\n")
str(model_data)
```

## 9.5 Fit Logistic Regression Model

```{r}
# Fit logistic regression model
logit_model <- glm(fraudulent ~ salary_standardized + desc_length_standardized +
                     missing_profile + entry_level + has_logo + has_questions +
                     telecommuting + california,
                   data = model_data,
                   family = binomial(link = "logit"))

cat("=== Logistic Regression Model Summary ===\n\n")
summary(logit_model)
```

## 9.6 Interpretation of Coefficients

```{r}
# Extract coefficients, standard errors, z-values, and p-values
coef_table <- summary(logit_model)$coefficients
coef_df <- as.data.frame(coef_table)
colnames(coef_df) <- c("Estimate", "Std.Error", "z.value", "p.value")

# Add odds ratios
coef_df$OddsRatio <- exp(coef_df$Estimate)

# Add confidence intervals for odds ratios
conf_int <- confint.default(logit_model)
coef_df$OR_CI_Lower <- exp(conf_int[,1])
coef_df$OR_CI_Upper <- exp(conf_int[,2])

# Add significance indicators
coef_df$Significant <- ifelse(coef_df$p.value < 0.001, "***",
                        ifelse(coef_df$p.value < 0.01, "**",
                        ifelse(coef_df$p.value < 0.05, "*",
                        ifelse(coef_df$p.value < 0.1, ".", ""))))

cat("=== Coefficient Interpretation ===\n\n")
print(round(coef_df, 4))
```

```{r}
cat("\n=== Odds Ratios with 95% Confidence Intervals ===\n\n")
cat("Signif. codes: '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1\n\n")

for (i in 1:nrow(coef_df)) {
  var_name <- rownames(coef_df)[i]
  or <- round(coef_df$OddsRatio[i], 4)
  ci_low <- round(coef_df$OR_CI_Lower[i], 4)
  ci_high <- round(coef_df$OR_CI_Upper[i], 4)
  sig <- coef_df$Significant[i]

  cat(sprintf("%-25s OR = %7.4f  [%7.4f, %7.4f] %s\n",
              var_name, or, ci_low, ci_high, sig))
}
```

## 9.7 Hypotheses About Predictors

Based on the interim report, we test the following directional hypotheses:

### (1) Salary Level

We expect unrealistically high salaries to be associated with a higher probability of fraud. $$
H_0: \beta_{sal} = 0 \quad \text{vs.} \quad H_1: \beta_{sal} > 0
$$

```{r}
# One-sided test for salary coefficient
beta_sal <- coef(logit_model)["salary_standardized"]
se_sal <- summary(logit_model)$coefficients["salary_standardized", "Std. Error"]
z_sal <- beta_sal / se_sal
p_sal_greater <- 1 - pnorm(z_sal)

cat("=== Hypothesis: Higher salary increases fraud odds ===\n")
cat("H0: beta_sal = 0 vs H1: beta_sal > 0\n\n")
cat("Coefficient:", round(beta_sal, 4), "\n")
cat("Std. Error:", round(se_sal, 4), "\n")
cat("Z-statistic:", round(z_sal, 4), "\n")
cat("P-value (one-sided):", format(p_sal_greater, scientific = TRUE, digits = 4), "\n")
cat("Odds Ratio:", round(exp(beta_sal), 4), "\n\n")

if (p_sal_greater < 0.05) {
  cat("Result: REJECT H0 - Higher salary significantly increases fraud odds.\n")
} else {
  cat("Result: FAIL TO REJECT H0 - No significant effect of salary on fraud.\n")
}
```

### (2) Missing Company Profile

Postings with missing company profiles are expected to be more likely to be fake. $$
H_0: \beta_{prof} = 0 \quad \text{vs.} \quad H_1: \beta_{prof} > 0
$$

```{r}
# One-sided test for missing profile coefficient
beta_prof <- coef(logit_model)["missing_profile"]
se_prof <- summary(logit_model)$coefficients["missing_profile", "Std. Error"]
z_prof_logit <- beta_prof / se_prof
p_prof_greater <- 1 - pnorm(z_prof_logit)

cat("=== Hypothesis: Missing profile increases fraud odds ===\n")
cat("H0: beta_prof = 0 vs H1: beta_prof > 0\n\n")
cat("Coefficient:", round(beta_prof, 4), "\n")
cat("Std. Error:", round(se_prof, 4), "\n")
cat("Z-statistic:", round(z_prof_logit, 4), "\n")
cat("P-value (one-sided):", format(p_prof_greater, scientific = TRUE, digits = 4), "\n")
cat("Odds Ratio:", round(exp(beta_prof), 4), "\n\n")

if (p_prof_greater < 0.05) {
  cat("Result: REJECT H0 - Missing profile significantly increases fraud odds.\n")
  cat("Interpretation: Postings with missing company profile have",
      round(exp(beta_prof), 2), "times the odds of being fraudulent.\n")
} else {
  cat("Result: FAIL TO REJECT H0 - No significant effect of missing profile on fraud.\n")
}
```

### (3) Length of Description

Extremely short descriptions are expected to be more suspicious, so longer descriptions may decrease fraud probability. $$
H_0: \beta_{len} = 0 \quad \text{vs.} \quad H_1: \beta_{len} < 0
$$

```{r}
# One-sided test for description length coefficient
beta_len <- coef(logit_model)["desc_length_standardized"]
se_len <- summary(logit_model)$coefficients["desc_length_standardized", "Std. Error"]
z_len <- beta_len / se_len
p_len_less <- pnorm(z_len)

cat("=== Hypothesis: Longer description decreases fraud odds ===\n")
cat("H0: beta_len = 0 vs H1: beta_len < 0\n\n")
cat("Coefficient:", round(beta_len, 4), "\n")
cat("Std. Error:", round(se_len, 4), "\n")
cat("Z-statistic:", round(z_len, 4), "\n")
cat("P-value (one-sided):", format(p_len_less, scientific = TRUE, digits = 4), "\n")
cat("Odds Ratio:", round(exp(beta_len), 4), "\n\n")

if (p_len_less < 0.05) {
  cat("Result: REJECT H0 - Longer description significantly decreases fraud odds.\n")
  cat("Interpretation: Each 1 SD increase in description length multiplies\n")
  cat("               the odds of fraud by", round(exp(beta_len), 4), "\n")
} else {
  cat("Result: FAIL TO REJECT H0 - No significant effect of description length on fraud.\n")
}
```

### (4) Entry-Level Experience

Scammers may target inexperienced candidates. $$
H_0: \beta_{entry} = 0 \quad \text{vs.} \quad H_1: \beta_{entry} > 0
$$

```{r}
# One-sided test for entry-level coefficient
beta_entry <- coef(logit_model)["entry_level"]
se_entry <- summary(logit_model)$coefficients["entry_level", "Std. Error"]
z_entry <- beta_entry / se_entry
p_entry_greater <- 1 - pnorm(z_entry)

cat("=== Hypothesis: Entry-level jobs have higher fraud odds ===\n")
cat("H0: beta_entry = 0 vs H1: beta_entry > 0\n\n")
cat("Coefficient:", round(beta_entry, 4), "\n")
cat("Std. Error:", round(se_entry, 4), "\n")
cat("Z-statistic:", round(z_entry, 4), "\n")
cat("P-value (one-sided):", format(p_entry_greater, scientific = TRUE, digits = 4), "\n")
cat("Odds Ratio:", round(exp(beta_entry), 4), "\n\n")

if (p_entry_greater < 0.05) {
  cat("Result: REJECT H0 - Entry-level positions have significantly higher fraud odds.\n")
} else {
  cat("Result: FAIL TO REJECT H0 - No significant effect of experience level on fraud.\n")
}
```

## 9.8 Model Diagnostics

```{r}
# Model fit statistics
cat("=== Model Fit Statistics ===\n\n")

# Log-likelihood
cat("Log-Likelihood:", round(logLik(logit_model)[1], 2), "\n")

# AIC and BIC
cat("AIC:", round(AIC(logit_model), 2), "\n")
cat("BIC:", round(BIC(logit_model), 2), "\n\n")

# Deviance
cat("Null Deviance:", round(logit_model$null.deviance, 2), "on", logit_model$df.null, "df\n")
cat("Residual Deviance:", round(logit_model$deviance, 2), "on", logit_model$df.residual, "df\n\n")

# McFadden's R-squared
null_model <- glm(fraudulent ~ 1, data = model_data, family = binomial)
mcfadden_r2 <- 1 - (logLik(logit_model)[1] / logLik(null_model)[1])
cat("McFadden's R-squared:", round(mcfadden_r2, 4), "\n")
```

```{r}
# Likelihood Ratio Test (overall model significance)
lr_stat <- logit_model$null.deviance - logit_model$deviance
lr_df <- logit_model$df.null - logit_model$df.residual
lr_pvalue <- 1 - pchisq(lr_stat, df = lr_df)

cat("\n=== Likelihood Ratio Test ===\n")
cat("H0: All coefficients = 0 (null model)\n")
cat("H1: At least one coefficient != 0\n\n")
cat("LR Statistic:", round(lr_stat, 2), "\n")
cat("Degrees of freedom:", lr_df, "\n")
cat("P-value:", format(lr_pvalue, scientific = TRUE, digits = 4), "\n\n")

if (lr_pvalue < 0.05) {
  cat("Result: REJECT H0 - The model is significantly better than the null model.\n")
} else {
  cat("Result: FAIL TO REJECT H0 - The model is not significantly better than the null.\n")
}
```

## 9.9 Prediction Performance

```{r}
# Predicted probabilities
model_data$predicted_prob <- predict(logit_model, type = "response")

# Classification at threshold 0.5
model_data$predicted_class <- ifelse(model_data$predicted_prob > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Actual = model_data$fraudulent, Predicted = model_data$predicted_class)

cat("=== Confusion Matrix (threshold = 0.5) ===\n\n")
print(conf_matrix)

# Performance metrics
TP <- conf_matrix[2, 2]
TN <- conf_matrix[1, 1]
FP <- conf_matrix[1, 2]
FN <- conf_matrix[2, 1]

accuracy <- (TP + TN) / sum(conf_matrix)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)  # Sensitivity
specificity <- TN / (TN + FP)
f1_score <- 2 * precision * recall / (precision + recall)

cat("\n=== Performance Metrics ===\n\n")
cat("Accuracy:", round(accuracy * 100, 2), "%\n")
cat("Precision:", round(precision * 100, 2), "%\n")
cat("Recall (Sensitivity):", round(recall * 100, 2), "%\n")
cat("Specificity:", round(specificity * 100, 2), "%\n")
cat("F1 Score:", round(f1_score, 4), "\n")
```

```{r fig.width=10, fig.height=5}
# ROC Curve (manual calculation)
thresholds <- seq(0, 1, by = 0.01)
roc_data <- data.frame(
  threshold = thresholds,
  TPR = sapply(thresholds, function(t) {
    pred <- ifelse(model_data$predicted_prob > t, 1, 0)
    sum(pred == 1 & model_data$fraudulent == 1) / sum(model_data$fraudulent == 1)
  }),
  FPR = sapply(thresholds, function(t) {
    pred <- ifelse(model_data$predicted_prob > t, 1, 0)
    sum(pred == 1 & model_data$fraudulent == 0) / sum(model_data$fraudulent == 0)
  })
)

# Calculate AUC using trapezoidal rule
roc_data <- roc_data[order(roc_data$FPR), ]
auc <- sum(diff(roc_data$FPR) * (head(roc_data$TPR, -1) + tail(roc_data$TPR, -1)) / 2)

ggplot(roc_data, aes(x = FPR, y = TPR)) +
  geom_line(color = "#e74c3c", size = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
  annotate("text", x = 0.7, y = 0.3, label = paste0("AUC = ", round(abs(auc), 4)), size = 5) +
  labs(title = "ROC Curve for Logistic Regression Model",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal() +
  coord_equal()
```

## 9.10 Summary of Logistic Regression Results

```{r}
cat("=== SUMMARY OF LOGISTIC REGRESSION ANALYSIS ===\n\n")

cat("MODEL FIT:\n")
cat("  McFadden's R-squared:", round(mcfadden_r2, 4), "\n")
cat("  AIC:", round(AIC(logit_model), 2), "\n")
cat("  Model is", ifelse(lr_pvalue < 0.05, "SIGNIFICANT", "NOT SIGNIFICANT"),
    "(LR test p-value:", format(lr_pvalue, scientific = TRUE, digits = 4), ")\n\n")

cat("SIGNIFICANT PREDICTORS (alpha = 0.05):\n")
sig_predictors <- rownames(coef_df)[coef_df$p.value < 0.05 & rownames(coef_df) != "(Intercept)"]
if (length(sig_predictors) > 0) {
  for (pred in sig_predictors) {
    or <- round(coef_df[pred, "OddsRatio"], 4)
    direction <- ifelse(coef_df[pred, "Estimate"] > 0, "increases", "decreases")
    cat("  -", pred, ": OR =", or, "(", direction, "fraud odds)\n")
  }
} else {
  cat("  None\n")
}

cat("\nPREDICTION PERFORMANCE:\n")
cat("  Accuracy:", round(accuracy * 100, 2), "%\n")
cat("  Precision:", round(precision * 100, 2), "%\n")
cat("  Recall:", round(recall * 100, 2), "%\n")
cat("  AUC:", round(abs(auc), 4), "\n")

cat("\nHYPOTHESES ABOUT PREDICTORS:\n")
cat("  (1) Salary -> fraud:", ifelse(p_sal_greater < 0.05, "SUPPORTED", "NOT SUPPORTED"), "\n")
cat("  (2) Missing profile -> fraud:", ifelse(p_prof_greater < 0.05, "SUPPORTED", "NOT SUPPORTED"), "\n")
cat("  (3) Longer desc -> less fraud:", ifelse(p_len_less < 0.05, "SUPPORTED", "NOT SUPPORTED"), "\n")
cat("  (4) Entry-level -> fraud:", ifelse(p_entry_greater < 0.05, "SUPPORTED", "NOT SUPPORTED"), "\n")
```
